{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml_class/mlad_spec/ml_on_labeled_data/week1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'/opt/ml_class/mlad_spec/ml_on_labeled_data/week1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%cd mlad_spec/ml_on_labeled_data/week1/\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = adver_data[['TV', 'Radio', 'Newspaper']].values\n",
    "y = adver_data['Sales'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means, stds = X.mean(axis=0), X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96985227,  0.98152247,  1.77894547]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = (X - means) / stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.96985227,  0.98152247,  1.77894547,  1.        ],\n       [-1.19737623,  1.08280781,  0.66957876,  1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.hstack((X, np.ones(200).reshape(200,1)))\n",
    "X[[0,1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return sum(map(lambda x1, x2: (x1-x2) ** 2, y, y_pred)) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, [np.median(y)] * len(y))\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    return np.dot(np.linalg.inv(np.dot(np.transpose(X), X)), np.dot(np.transpose(X), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = np.dot([0, 0, 0, 1], norm_eq_weights)\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    l = len(y)\n",
    "    x_k = X[train_ind]\n",
    "    y_k = y[train_ind]\n",
    "    return w + 2*eta/l*x_k*(y_k - np.dot(w, x_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        w_next = stochastic_gradient_step(X, y, w, random_ind, eta)\n",
    "        y_pred = linear_prediction(X, w_next)\n",
    "        errors.append(mserror(y, y_pred))\n",
    "        \n",
    "        weight_dist = np.linalg.norm(w - w_next)\n",
    "        \n",
    "        iter_num += 1\n",
    "        w = w_next\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.9 s, sys: 72 ms, total: 26.9 s\nWall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, np.zeros(4), max_iter = 1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f6a822bc810>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAF9CAYAAAAjuOMbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a8e93fb90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.91069256e+00,   2.78209808e+00,  -8.10462217e-03,\n         1.40190566e+01])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7844125884067039"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78441258841\n"
     ]
    }
   ],
   "source": [
    "answer4 = stoch_errors_by_iter[-1]\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}